{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856e68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEL architecture\n",
    "alpha = 0.33\n",
    "d = [8, 16, 24, 32, 64,128,256,512] \n",
    "def create_model(input_shape, d):\n",
    "    model = Sequential()\n",
    "    for k in range(4):\n",
    "        if( k==0 ):\n",
    "            model.add(Conv2D(d[0], (3, 3), input_shape=input_shape,padding='same'))\n",
    "\n",
    "        else:\n",
    "            model.add(Conv2D(d[2*k], (3, 3),padding='same'))\n",
    "        model.add(Conv2D(d[2*k+1],(3,3),padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.99))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3),padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ccfd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODGD architecture \n",
    "f = [32, 64, 128, 256] \n",
    "def create_model(input_shape, f):\n",
    "    model = Sequential()\n",
    "    for i in range(len(f)):\n",
    "        if(i==0):\n",
    "            model.add(Conv2D(f[i], (3, 3), input_shape=input_shape,padding='same' ))\n",
    "            \n",
    "        else:\n",
    "            model.add(Conv2D(f[i], (3, 3), padding='same'))  \n",
    "        model.add(ReLU())\n",
    "        model.add(BatchNormalization(momentum=0.99))\n",
    "        model.add(MaxPooling2D(pool_size=(3, 3),padding='same'))\n",
    "        model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43f7420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODGDGRAM CRNN--------------------------------------------------------(ISMIR )\n",
    "j = [32, 64, 128] \n",
    "def ReshapeLayer(x):\n",
    "    \n",
    "    shape = x.shape\n",
    "    \n",
    "    # 1 possibility: H,W*channel\n",
    "    #reshape = Reshape((shape[1],shape[2]*shape[3]))(x)\n",
    "    \n",
    "    # 2 possibility: W,H*channel\n",
    "    transpose = Permute((2,1,3))(x)\n",
    "    reshape = Reshape((shape[1],shape[2]*shape[3]))(transpose)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "\n",
    "def right_cmmr_crnn(input_shape, j):\n",
    "    model = Sequential()\n",
    "    for k in range(3):\n",
    "        if(k == 0):\n",
    "            model.add(Conv2D(j[0], (3, 3), input_shape=input_shape, padding='same'))\n",
    "        else:\n",
    "            model.add(Conv2D(j[ k], (3, 3), padding='same'))\n",
    "        model.add(ReLU())\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Lambda(ReshapeLayer))\n",
    "    model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(32)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0544a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE\n",
    "# SIMPLE MEL CRNN (ISMIR)\n",
    "def ReshapeLayer(x):\n",
    "    \n",
    "    shape = x.shape\n",
    "    # 1 possibility: H,W*channel\n",
    "    #reshape = Reshape((shape[1],shape[2]*shape[3]))(x)\n",
    "    \n",
    "    # 2 possibility: W,H*channel\n",
    "    transpose = Permute((2,1,3))(x)\n",
    "    reshape = Reshape((shape[1],shape[2]*shape[3]))(transpose)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "\n",
    "\n",
    "def left_cmmr_crnn_simple(input_shape, h):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Convolutional block\n",
    "    model.add(Conv2D(12, (3, 3), input_shape=input_shape, padding='same'))\n",
    "\n",
    "    #Max Pooling\n",
    "    model.add( MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) \n",
    "    \n",
    "    #Reccurent block\n",
    "    model.add(Lambda(ReshapeLayer))\n",
    "    model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(32)))\n",
    "\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  (CRNN) ( ISMIR MEL)\n",
    "h = [8, 16, 32, 64, 128, 256] \n",
    "\n",
    "def left_cmmr_crnn(input_shape, h):\n",
    "    model = Sequential()\n",
    "    for k in range(3):\n",
    "        if(k == 0):\n",
    "            model.add(Conv2D(h[0], (3, 3), input_shape=input_shape, padding='same'))\n",
    "        else:\n",
    "            model.add(Conv2D(h[2 * k], (3, 3), padding='same'))\n",
    "        model.add(Conv2D(h[2 * k + 1], (3, 3), padding='same'))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Lambda(ReshapeLayer))\n",
    "    model.add(Bidirectional(GRU(32, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(32)))\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3ed738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENTION-----\n",
    "\n",
    "h = [8, 16, 32, 64, 128, 256] \n",
    "\n",
    "def attention_left_cmmr_crnn(input_shape, h):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for k in range(2):\n",
    "        if(k == 0):\n",
    "            x = Conv2D(h[0], (3, 3), padding='same')(x)\n",
    "        else:\n",
    "            x = Conv2D(h[2 * k], (3, 3), padding='same')(x)\n",
    "        x = Conv2D(h[2 * k + 1], (3, 3), padding='same')(x)\n",
    "        x = LeakyReLU(alpha=alpha)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    x = Lambda(ReshapeLayer)(x)\n",
    "    x = Bidirectional(GRU(32, return_sequences=True))(x)\n",
    "    x = Bidirectional(GRU(32, return_sequences=True))(x)\n",
    "    \n",
    "    # Split output of last GRU layer into two tensors\n",
    "    #query, value = tf.split(x, num_or_size_splits=2, axis=2)\n",
    "    attention_output = Attention()([x, x])\n",
    "    \n",
    "    x = Flatten()(attention_output)\n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(11, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d143d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWIN TRANSFORMER\n",
    "\n",
    "input_size = (128, 128, 1) # The image size of the MNIST\n",
    "patch_size = (4, 4) # Segment 28-by-28 frames into 2-by-2 sized patches, patch contents and positions are embedded\n",
    "n_labels = 11 # MNIST labels\n",
    "\n",
    "\n",
    "mlp_drop_rate = 0.01 # Droupout after each MLP layer\n",
    "attn_drop_rate = 0.01 # Dropout after Swin-Attention\n",
    "proj_drop_rate = 0.01 # Dropout at the end of each Swin-Attention block, i.e., after linear projections\n",
    "drop_path_rate = 0.01 # Drop-path within skip-connections\n",
    "\n",
    "# Self-attention parameters \n",
    "# (Fixed for all the blocks in this configuration, but can vary per block in larger architectures)\n",
    "num_heads = 8 # Number of attention heads\n",
    "embed_dim = 96 # Number of embedded dimensions\n",
    "num_mlp = 256 # Number of MLP nodes\n",
    "qkv_bias = True # Convert embedded patches to query, key, and values with a learnable additive value\n",
    "qk_scale = None # None: Re-scale query based on embed dimensions per attention head # Float for user specified scaling factor\n",
    "\n",
    "# Shift-window parameters\n",
    "window_size = 4 # Size of attention window (height = width)\n",
    "shift_size = window_size // 2 # Size of shifting (shift_size < window_size)\n",
    "\n",
    "num_patch_x = input_size[0]//patch_size[0]\n",
    "num_patch_y = input_size[1]//patch_size[1]\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "\n",
    "\n",
    "with tf.device(device_name):\n",
    "    # The input section\n",
    "    IN = Input(input_size)\n",
    "    X = IN\n",
    "\n",
    "    # Extract patches from the input tensor\n",
    "    X = transformer_layers.patch_extract(patch_size)(X)\n",
    "\n",
    "    # Embed patches to tokens\n",
    "    X = transformer_layers.patch_embedding(num_patch_x*num_patch_y, embed_dim)(X)\n",
    "    # -------------------- Swin transformers -------------------- #\n",
    "    # Stage 1: window-attention + Swin-attention + patch-merging\n",
    "\n",
    "    for i in range(2):\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            shift_size_temp = 0\n",
    "        else:\n",
    "            shift_size_temp = shift_size\n",
    "\n",
    "        X = swin_layers.SwinTransformerBlock(dim=embed_dim, num_patch=(num_patch_x, num_patch_y), num_heads=num_heads, \n",
    "                                window_size=window_size, shift_size=shift_size_temp, num_mlp=num_mlp, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                mlp_drop=mlp_drop_rate, attn_drop=attn_drop_rate, proj_drop=proj_drop_rate, drop_path_prob=drop_path_rate, \n",
    "                                name='swin_block{}'.format(i))(X)\n",
    "    # Patch-merging\n",
    "    # Pooling patch sequences. Half the number of patches (skip every two patches) and double the embedded dimensions\n",
    "    X = transformer_layers.patch_merging((num_patch_x, num_patch_y), embed_dim=embed_dim, name='down{}'.format(i))(X)\n",
    "\n",
    "    # ----------------------------------------------------------- #\n",
    "\n",
    "    # Convert embedded tokens (2D) to vectors (1D)\n",
    "    X = GlobalAveragePooling1D()(X)\n",
    "\n",
    "    # The output section\n",
    "    OUT = Dense(n_labels, activation='softmax')(X)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[IN,], outputs=[OUT,])\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "         learning_rate=learning_rate, weight_decay=weight_decay\n",
    "     )\n",
    "\n",
    "    model.compile(\n",
    "         optimizer=optimizer,\n",
    "         loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "         metrics=[\n",
    "             keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "             keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "         ],\n",
    "    )\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=2)\n",
    "    checkpoint_filepath = \"\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "         checkpoint_filepath,\n",
    "         monitor=\"accuracy\",\n",
    "         save_best_only=True,\n",
    "         save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "         x=x_train,\n",
    "         y=y_train,\n",
    "         batch_size=32,\n",
    "         validation_data=(x_test, y_test),\n",
    "         epochs=100,\n",
    "         callbacks=[checkpoint_callback,early_stop],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "    #Compile the model\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-3, clipvalue=0.5)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c217063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISION TRANSFORMER\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 8\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 16\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n",
    "\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "       layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.1, width_factor=0.1\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n",
    "\n",
    "\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "    \n",
    "    \n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(x_test,y_test),\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    #print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    #print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "   \n",
    "with tf.device(device_name):\n",
    "    vit_classifier = create_vit_classifier()\n",
    "    history = run_experiment(vit_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
